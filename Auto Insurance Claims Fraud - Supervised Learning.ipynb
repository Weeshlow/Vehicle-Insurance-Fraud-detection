{
  "metadata": {
    "name": "Auto Insurance Claims Fraud - Supervised Learning",
    "kernelspec": {
      "language": "scala",
      "name": "spark2-scala"
    },
    "language_info": {
      "codemirror_mode": "text/x-scala",
      "file_extension": ".scala",
      "mimetype": "text/x-scala",
      "name": "scala",
      "pygments_lexer": "scala"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## Auto Insurance Claims Fraud - Supervised Learning\n\nNearly one in 10 Americans would commit insurance fraud if they knew they could get away with it. Nearly one in four Americans say it’s ok to defraud insurers.   About one in 10 people agree it’s ok to submit claims for items that aren’t lost or damaged, or for personal injuries that didn’t occur. Two in five people are “not very likely” or “not likely at all” to report someone who ripped of an insurer. \n\\- Accenture Ltd.(2003)   \n\nNearly three of 10 Americans (29 percent) wouldn\u0027t report insurance scams committed by someone they know. \n\\- Progressive Insurance (2001)\n\nThis notebook shows how to \"flag\" fraudulent insurance claims based on past known cases using several supervised learning algorithms (Random Forest, Decision Tree, SVM, GLM). These models can be evaluated using a variety of metrics, including generating a lift chart. Computations on data occur inside Autonomous Database, leveraging it as a high-performance compute engine.\n\nCopyright (c) 2021 Oracle Corporation \n###### \u003ca href\u003d\"https://oss.oracle.com/licenses/upl/\" onclick\u003d\"return ! window.open(\u0027https://oss.oracle.com/licenses/upl/\u0027);\"\u003eThe Universal Permissive License (UPL), Version 1.0\u003c/a\u003e\n---"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": " \n![tiny arrow](http://www.oracle.com/technetwork/database/options/advanced-analytics/autoinsurancepic60-5434493.jpg \"tiny arrow\")\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## Business Problem\n\n---\nBased on \"labeled data\" derived from automobile insurance claims evaluators (see related Auto Insurance Claims Fraud - Unsupervised Learning OML Notebook), we can now build supervised learning models that better target known insurance claims fraud.   Based on this historical \"labeled data\" (Fraudfound Yes/No), we would like to build predictive models to detect likely fraudulent auto claims."
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%python\n\nimport pandas as pd\nimport oml"
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%python\n\n# URL of the location of the data in CSV format\nurl\u003d\"https://raw.githubusercontent.com/oracle/oracle-db-examples/master/machine-learning/datasets/CLAIMS.csv\"\n\n# Create a local Pandas Dataframe\nclaims_pd \u003d pd.read_csv(url)\n\n# Check the number of rows and columns of the PD\nclaims_pd.shape"
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%python\n\n# Ensure a table with that name does not exist\ntry:\n    oml.drop(table\u003d\u0027CLAIMS\u0027)\nexcept:\n    pass\n    \nclaims_pd \u003d claims_pd.rename(columns \u003d {\"DAYS:POLICY-ACCIDENT\": \u0027DAYSPOLICYACCIDENT\u0027, \u0027DAYS:POLICY-CLAIM\u0027: \u0027DAYSPOLICYCLAIM\u0027, \u0027ADDRESSCHANGE-CLAIM\u0027: \u0027ADDRESSCHANGECLAIM\u0027})\n\n# Create the table CLAIMS and get back a proxy object CLAIMS_DF    \nCLAIMS_DF \u003d oml.create(claims_pd, table \u003d \u0027CLAIMS\u0027)"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "### Display the newly imported data using both Python and SQL\n---\n"
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%python\n\nz.show(CLAIMS_DF)"
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%sql \n\nSELECT * FROM CLAIMS;"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## Data Understanding\n\n---\nIn this section, we use the built-in notebook visualization capabilities to explore the data."
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%sql\nSELECT * from CLAIMS;"
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%sql\n\nSELECT * from CLAIMS;"
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%sql\n\nSELECT * from CLAIMS;"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## Data Preparation\n\n---"
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%script\r\n\r\n-- Split the data into random samples of 60% for training data (CLAIMS_TRAIN_DATA) for training the models \r\n-- and a 40% hold out sample for testing and evaluating the models (CLAIMS_TEST_DATA)\r\n\r\nCREATE OR REPLACE VIEW CLAIMS_TRAIN_DATA AS SELECT * FROM CLAIMS SAMPLE (60) SEED (1);\r\nCREATE OR REPLACE VIEW CLAIMS_TEST_DATA AS SELECT * FROM CLAIMS MINUS SELECT * FROM CLAIMS_TRAIN_DATA;"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## Data Transformation using Python \n---\n\nThe OML4Py Transparency Layer transforms data in the database instance, without extracting data. "
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "### One-hot encoding\n\n---\n\nThe OML in-database algorithms provide algorithm-specific automatic data preparation. One of the transformations involve categorical columns that must be one-hot encoded (or \"exploded\"). The following paragraphs demonstrate how to achieve one-hot encoding explicitly using OML4Py on a database table, however, one-hot encoding occurs automatically if PREP_AUTO is set to ON for model building.  \n"
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%python\n\nCLAIMS_TRAIN_DF \u003d oml.sync(view \u003d \u0027CLAIMS_TRAIN_DATA\u0027)\ncategorical_cols \u003d [\u0027MARITALSTATUS\u0027, \u0027MAKE\u0027, \u0027SEX\u0027, \u0027BASEPOLICY\u0027]\nCLAIMS_TRAIN_CAT_DF \u003d CLAIMS_TRAIN_DF[[\u0027POLICYNUMBER\u0027] + categorical_cols]\n\nz.show(CLAIMS_TRAIN_CAT_DF.head(20))"
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%python\n\ndef encode(DF, ids, col):\n    assert isinstance(ids, list)\n    CNT_DF \u003d DF.crosstab(ids, col)\n    PIVOT_DF \u003d CNT_DF.pivot_table(ids, col, \u0027count\u0027, aggfunc \u003d oml.DataFrame.count)\n    cols \u003d PIVOT_DF.columns[len(ids):]\n    new_columns \u003d [ col + \u0027_\u0027 + c.split(\u0027_\u0027)[1][1:-1] for c in cols]\n    new_columns \u003d ids + new_columns\n    PIVOT_DF.rename(columns \u003d new_columns)\n    return PIVOT_DF"
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%python\n\nONEHOT_DF \u003d encode(CLAIMS_TRAIN_CAT_DF, [\u0027POLICYNUMBER\u0027], \u0027MARITALSTATUS\u0027)    \n\nz.show(ONEHOT_DF.head())"
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%python\n\nRES_DF \u003d CLAIMS_TRAIN_CAT_DF[[\u0027POLICYNUMBER\u0027]]\nfor i, col in enumerate(categorical_cols):\n    if col \u003d\u003d \u0027POLICYNUMBER\u0027:\n        continue\n    ONEHOT_DF \u003d encode(CLAIMS_TRAIN_CAT_DF, [\u0027POLICYNUMBER\u0027], col)\n    RES_DF \u003d RES_DF.merge(ONEHOT_DF, on \u003d\u0027POLICYNUMBER\u0027, how \u003d \u0027inner\u0027, suffixes \u003d [\u0027\u0027, \u0027\u0027])\n    \nz.show(RES_DF.head())"
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%python\n\ncols \u003d RES_DF.columns[1:]\nfor col in cols:\n    RES_DF \u003d RES_DF.replace(old \u003d [None], new \u003d [0.0], default \u003d 1.0, columns \u003d [col])\n    \nz.show(RES_DF.head())"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## Model Building\n\n---\nFirst, we use the Attribute Importance algorithm to rank the attributes (predictor columns) according to how they predict the target, FRAUDFOUND. After filtering columns based on the most predictive, we build 4 models using OML4SQL using RandomForest, GLM, SVM, and Decision Tree in-database algorithms. The default options are used here, however, there are various settings users may provide. Below, we highlight those settings for Decision Tree. "
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%script\n\n--  Find the importance of attributes that impact the target FRAUDFOUND\n\nBEGIN DBMS_DATA_MINING.DROP_MODEL(\u0027AI_EXPLAIN_OUTPUT_CLAIMS_AI\u0027);\nEXCEPTION WHEN OTHERS THEN NULL; END;\n\nDECLARE\n    V_SETLST DBMS_DATA_MINING.SETTING_LIST;\nBEGIN\n    V_SETLST(\u0027ALGO_NAME\u0027)        :\u003d \u0027ALGO_AI_MDL\u0027;\n    V_SETLST(\u0027PREP_AUTO\u0027)        :\u003d \u0027ON\u0027;\n\n    DBMS_DATA_MINING.CREATE_MODEL2(\n        MODEL_NAME        \u003d\u003e \u0027AI_EXPLAIN_OUTPUT_CLAIMS_AI\u0027,\n        MINING_FUNCTION   \u003d\u003e \u0027ATTRIBUTE_IMPORTANCE\u0027,\n        DATA_QUERY        \u003d\u003e \u0027SELECT * FROM CLAIMS\u0027,\n        SET_LIST          \u003d\u003e V_SETLST,\n        CASE_ID_COLUMN_NAME \u003d\u003e \u0027POLICYNUMBER\u0027,\n        TARGET_COLUMN_NAME  \u003d\u003e \u0027FRAUDFOUND\u0027);\nEND;\n"
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%sql\n\nSELECT * FROM DM$VAAI_EXPLAIN_OUTPUT_CLAIMS_AI ORDER BY ATTRIBUTE_IMPORTANCE_VALUE DESC FETCH FIRST 8 ROWS ONLY;\n"
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%sql\n\n-- Add Filtered dataset for Model generation, \n-- keeping Policy Number as well as FraudFound (the Target)\n\nCREATE OR REPLACE VIEW CLAIMS_TRAIN_DATA_FILTERED AS \nSELECT POLICYNUMBER,\n       BASEPOLICY, \n       VEHICLECATEGORY, \n       FAULT, \n       PASTNUMBEROFCLAIMS, \n       VEHICLEPRICE, \n       WITNESSPRESENT,\n       AGEOFPOLICYHOLDER,\n       MARITALSTATUS,\n       FRAUDFOUND\nFROM CLAIMS_TRAIN_DATA;"
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%script\n\n\nBEGIN\n    DBMS_DATA_MINING.DROP_MODEL(\u0027CLAIMS_CLASS_MODEL_RF\u0027);\n    EXCEPTION WHEN OTHERS THEN NULL; \nEND;\n\nDECLARE\n    V_SETLST DBMS_DATA_MINING.SETTING_LIST;\nBEGIN\n    V_SETLST(\u0027PREP_AUTO\u0027) :\u003d \u0027ON\u0027;\n    V_SETLST(\u0027ALGO_NAME\u0027) :\u003d \u0027ALGO_RANDOM_FOREST\u0027;\n    DBMS_DATA_MINING.CREATE_MODEL2(\n        \u0027CLAIMS_CLASS_MODEL_RF\u0027,\n        \u0027CLASSIFICATION\u0027,\n        \u0027SELECT * FROM CLAIMS_TRAIN_DATA_FILTERED\u0027,\n        V_SETLST,\n        \u0027POLICYNUMBER\u0027,\n        \u0027FRAUDFOUND\u0027);\nEND;\n\n"
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%script\n\n\nBEGIN\n    DBMS_DATA_MINING.DROP_MODEL(\u0027CLAIMS_CLASS_MODEL_GLM\u0027);\n    EXCEPTION WHEN OTHERS THEN NULL; \nEND;\n\nDECLARE\n    V_SETLST DBMS_DATA_MINING.SETTING_LIST;\nBEGIN\n    V_SETLST(\u0027PREP_AUTO\u0027) :\u003d \u0027ON\u0027;\n    V_SETLST(\u0027ALGO_NAME\u0027) :\u003d \u0027ALGO_GENERALIZED_LINEAR_MODEL\u0027;\n    DBMS_DATA_MINING.CREATE_MODEL2(\n        \u0027CLAIMS_CLASS_MODEL_GLM\u0027,\n        \u0027CLASSIFICATION\u0027,\n        \u0027SELECT * FROM CLAIMS_TRAIN_DATA_FILTERED\u0027,\n        V_SETLST,\n        \u0027POLICYNUMBER\u0027,\n        \u0027FRAUDFOUND\u0027);\nEND;\n\n"
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%script\n\nBEGIN\n    DBMS_DATA_MINING.DROP_MODEL(\u0027CLAIMS_CLASS_MODEL_SVM\u0027);\n    EXCEPTION WHEN OTHERS THEN NULL; \nEND;\n\nDECLARE\n    V_SETLST DBMS_DATA_MINING.SETTING_LIST;\nBEGIN\n    V_SETLST(\u0027PREP_AUTO\u0027) :\u003d \u0027ON\u0027;\n    V_SETLST(\u0027ALGO_NAME\u0027) :\u003d \u0027ALGO_SUPPORT_VECTOR_MACHINES\u0027;\n    DBMS_DATA_MINING.CREATE_MODEL2(\n        \u0027CLAIMS_CLASS_MODEL_SVM\u0027,\n        \u0027CLASSIFICATION\u0027,\n        \u0027SELECT * FROM CLAIMS_TRAIN_DATA_FILTERED\u0027,\n        V_SETLST,\n        \u0027POLICYNUMBER\u0027,\n        \u0027FRAUDFOUND\u0027);\nEND;\n\n"
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%script\n\n\nBEGIN\n    DBMS_DATA_MINING.DROP_MODEL(\u0027CLAIMS_CLASS_MODEL_DT\u0027);\n    EXCEPTION WHEN OTHERS THEN NULL; \nEND;\n\nDECLARE\n    V_SETLST DBMS_DATA_MINING.SETTING_LIST;\nBEGIN\n    V_SETLST(\u0027PREP_AUTO\u0027) :\u003d \u0027ON\u0027;\n    V_SETLST(\u0027ALGO_NAME\u0027) :\u003d \u0027ALGO_DECISION_TREE\u0027;\n    DBMS_DATA_MINING.CREATE_MODEL2(\n        \u0027CLAIMS_CLASS_MODEL_DT\u0027,\n        \u0027CLASSIFICATION\u0027,\n        \u0027SELECT * FROM CLAIMS_TRAIN_DATA_FILTERED\u0027,\n        V_SETLST,\n        \u0027POLICYNUMBER\u0027,\n        \u0027FRAUDFOUND\u0027);\nEND;\n\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "### Additional Options \n\n---\nAbove, we have produced a basic model using default hyperparameters. OML in-database algorithms provide a wide range of model hyperparameters, which can be selected and tuned depending on your data and use case.\n\nPlease refer to \u003ca href\u003d\"https://docs.oracle.com/en/database/oracle/oracle-database/21/arpls/DBMS_DATA_MINING.html#GUID-8987EE6F-41A9-4DF9-997C-129B41FDC59\" onclick\u003d\"return ! window.open(\u0027https://docs.oracle.com/en/database/oracle/oracle-database/21/arpls/DBMS_DATA_MINING.html#GUID-8987EE6F-41A9-4DF9-997C-129B41FDC59\u0027);\"\u003e this link \u003c/a\u003e for more information."
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "### Examples of possible setting overrides for Decision Tree \n\n---\n*Experiment with tweaking settings for other algorithms as well.*\n\nIf the user does not override the default settings, relevant settings are determined by the algorithm.\n\nA complete list of settings can be found in the documentation:\n\n-- Algorithm Settings: \u003ca href\u003d\"https://oracle.com/goto/ml-decision-tree\" onclick\u003d\"return ! window.open(\u0027https://oracle.com/goto/ml-decision-tree\u0027);\"\u003eDecision Tree\u003c/a\u003e \n\n-- Shared Settings: \u003ca href\u003d\"https://docs.oracle.com/en/database/oracle/machine-learning/oml4py/1/mlpug/shared-settings.html#GUID-2EFF3880-F2E2-4449-A8CC-2CF516DD096B\" onclick\u003d\"return ! window.open(\u0027https://docs.oracle.com/en/database/oracle/machine-learning/oml4py/1/mlpug/shared-settings.html#GUID-2EFF3880-F2E2-4449-A8CC-2CF516DD096B\u0027);\"\u003eAll algorithms\u003c/a\u003e\n\n\n-- Specify a row weight column \n    \u0027ODMS_ROW_WEIGHT_COLUMN_NAME\u0027 : \u0027\u003crow_weight_column_name\u003e\u0027\n   \n-- Specify a missing value treatment method for the training data. This setting does not affect the scoring data. The default value is `ODMS_MISSING_VALUE_AUTO`.  The option `ODMS_MISSING_VALUE_MEAN_MODE` replaces missing values with the mean (numeric attributes) or the mode (categorical attributes) both at build time and apply time where appropriate. The option `ODMS_MISSING_VALUE_AUTO` performs different strategies for different algorithms.  When `ODMS_MISSING_VALUE_TREATMENT` is set to `ODMS_MISSING_VALUE_DELETE_ROW`, the rows in the training data that contain missing values are deleted. However, if you want to replicate this missing value treatment in the scoring data, then you must perform the transformation explicitly.\n    \u0027ODMS_MISSING_VALUE_TREATMENT\u0027 : \u0027ODMS_MISSING_VALUE_AUTO\u0027\n    \n-- Specify Tree impurity metric for Decision Tree. \n   Tree algorithms seek the best test question for splitting data at each node. The best splitter and split values are those that result in the largest increase in target value homogeneity (purity) for the entities in the node. Purity is by a metric. Decision trees can use either Gini `TREE_IMPURITY_GINI` or entropy `TREE_IMPURITY_ENTROPY` as the purity metric. By default, the algorithm uses `TREE_IMPURITY_GINI`.\n    \u0027TREE_IMPURITY_METRIC\u0027 : \u0027TREE_IMPURITY_GINI\u0027\n    \n-- Specify the criteria for splits regarding the maximum tree depth (the maximum number of nodes between the root and any leaf node, including the leaf node).\n   For Decision Tree, it requires a number between 2 and 20, and the default is 7. For Random Forest it is a number between 2 and 100, and the default is 16.\n    \u0027TREE_TERM_MAX_DEPTH\u0027 : \u00277\u0027\n    \n-- Specify the minimum number of training rows in a node expressed as a percentage of the rows in the training data.\n   It requires a number between 0 and 10.  The default is 0.05, indicating 0.05%. \n    \u0027TREE_TERM_MINPCT_NODE\u0027 : \u00270.05\u0027\n    \n-- Specifyt he minimum number of rows required to consider splitting a node expressed as a percentage of the training rows.\n   It requires a number greater than 0, and smaller or equal to 20.  The default is 0.1, indicating 0.1%. \n    \u0027TREE_TERM_MINPCT_SPLIT\u0027 : \u00270.1\u0027\n\n-- Specify The minimum number of rows in a node.\n   It requires a number greater than or equal to zero. The default is 10.      \n    \u0027TREE_TERM_MINREC_NODE\u0027 : \u002710\u0027\n    \n-- Specify the criteria for splits regarding the minimum number of records in a parent node expressed as a value. \n   No split is attempted if the number of records is below this value.  It requires a number greater than 1.  The default is 20.       \n    \u0027TREE_TERM_MINREC_SPLIT\u0027 : \u002720\u0027\n    \n-- Specify the maximum number of bins for each attribute.\n   For Decision Tree it requires a number between 2 and 2,147,483,647, with the default value of 32. For Random Forest it requires a number between 2 and 254, with the default value of 32.\n    \u0027CLAS_MAX_SUP_BINS\u0027 : \u002732\u0027"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## Model Evaluation\n\n---\n\nThere are many ways to compute model evaluation statistics. One is to use the COMPUTE_LIFT procedure from the DBMS_DATA_MINING library. We\u0027ll combine the results from each of the models to display an integrated lift chart. We use the native notebook visualization as well as Python using matplotlib. "
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%script\n\n-- Drop apply result and lift tables\nBEGIN EXECUTE IMMEDIATE \u0027DROP TABLE CLAIMS_APPLY_RESULT_RF PURGE\u0027;\nEXCEPTION WHEN OTHERS THEN NULL; END;\n/\nBEGIN EXECUTE IMMEDIATE \u0027DROP TABLE CLAIMS_LIFT_TABLE_RF PURGE\u0027;\nEXCEPTION WHEN OTHERS THEN NULL; END;\n/\n    \n-- Score the data and compute lift\nBEGIN\n    DBMS_DATA_MINING.APPLY(\u0027CLAIMS_CLASS_MODEL_RF\u0027,\u0027CLAIMS_TEST_DATA\u0027,\u0027POLICYNUMBER\u0027,\u0027CLAIMS_APPLY_RESULT_RF\u0027);\n    DBMS_DATA_MINING.COMPUTE_LIFT(\u0027CLAIMS_APPLY_RESULT_RF\u0027,\u0027CLAIMS_TEST_DATA\u0027,\u0027POLICYNUMBER\u0027,\u0027FRAUDFOUND\u0027,\u0027CLAIMS_LIFT_TABLE_RF\u0027,\u0027Yes\u0027,\u0027PREDICTION\u0027,\u0027PROBABILITY\u0027,100);\nEND;\n"
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%script\n\n-- Drop apply result and lift tables\nBEGIN EXECUTE IMMEDIATE \u0027DROP TABLE CLAIMS_APPLY_RESULT_GLM PURGE\u0027;\nEXCEPTION WHEN OTHERS THEN NULL; END;\n/\nBEGIN EXECUTE IMMEDIATE \u0027DROP TABLE CLAIMS_LIFT_TABLE_GLM PURGE\u0027;\nEXCEPTION WHEN OTHERS THEN NULL; END;\n/\n    \n-- Score the data and compute lift\nBEGIN\n    DBMS_DATA_MINING.APPLY(\u0027CLAIMS_CLASS_MODEL_GLM\u0027,\u0027CLAIMS_TEST_DATA\u0027,\u0027POLICYNUMBER\u0027,\u0027CLAIMS_APPLY_RESULT_GLM\u0027);\n    DBMS_DATA_MINING.COMPUTE_LIFT(\u0027CLAIMS_APPLY_RESULT_GLM\u0027,\u0027CLAIMS_TEST_DATA\u0027,\u0027POLICYNUMBER\u0027,\u0027FRAUDFOUND\u0027,\u0027CLAIMS_LIFT_TABLE_GLM\u0027,\u0027Yes\u0027,\u0027PREDICTION\u0027,\u0027PROBABILITY\u0027,100);\nEND;\n"
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%script\n\n-- Drop apply result and lift tables\nBEGIN EXECUTE IMMEDIATE \u0027DROP TABLE CLAIMS_APPLY_RESULT_SVM PURGE\u0027;\nEXCEPTION WHEN OTHERS THEN NULL; END;\n/\nBEGIN EXECUTE IMMEDIATE \u0027DROP TABLE CLAIMS_LIFT_TABLE_SVM PURGE\u0027;\nEXCEPTION WHEN OTHERS THEN NULL; END;\n/\n    \n-- Score the data and compute lift\nBEGIN\n    DBMS_DATA_MINING.APPLY(\u0027CLAIMS_CLASS_MODEL_SVM\u0027,\u0027CLAIMS_TEST_DATA\u0027,\u0027POLICYNUMBER\u0027,\u0027CLAIMS_APPLY_RESULT_SVM\u0027);\n    DBMS_DATA_MINING.COMPUTE_LIFT(\u0027CLAIMS_APPLY_RESULT_SVM\u0027,\u0027CLAIMS_TEST_DATA\u0027,\u0027POLICYNUMBER\u0027,\u0027FRAUDFOUND\u0027,\u0027CLAIMS_LIFT_TABLE_SVM\u0027,\u0027Yes\u0027,\u0027PREDICTION\u0027,\u0027PROBABILITY\u0027,100);\nEND;\n"
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%script\n\n-- Drop apply result and lift tables\nBEGIN EXECUTE IMMEDIATE \u0027DROP TABLE CLAIMS_APPLY_RESULT_DT PURGE\u0027;\nEXCEPTION WHEN OTHERS THEN NULL; END;\n/\nBEGIN EXECUTE IMMEDIATE \u0027DROP TABLE CLAIMS_LIFT_TABLE_DT PURGE\u0027;\nEXCEPTION WHEN OTHERS THEN NULL; END;\n/\n    \n-- Score the data and compute lift\nBEGIN\n    DBMS_DATA_MINING.APPLY(\u0027CLAIMS_CLASS_MODEL_DT\u0027,\u0027CLAIMS_TEST_DATA\u0027,\u0027POLICYNUMBER\u0027,\u0027CLAIMS_APPLY_RESULT_DT\u0027);\n    DBMS_DATA_MINING.COMPUTE_LIFT(\u0027CLAIMS_APPLY_RESULT_DT\u0027,\u0027CLAIMS_TEST_DATA\u0027,\u0027POLICYNUMBER\u0027,\u0027FRAUDFOUND\u0027,\u0027CLAIMS_LIFT_TABLE_DT\u0027,\u0027Yes\u0027,\u0027PREDICTION\u0027,\u0027PROBABILITY\u0027,100);\nEND;\n\n"
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%sql\n\nSELECT *\nFROM CLAIMS_LIFT_TABLE_DT"
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%sql\n\nCREATE OR REPLACE VIEW ALL_LIFT_DATA AS \nSELECT QUANTILE_NUMBER, ROUND(GAIN_CUMULATIVE*100,2) GAIN_CUMULATIVE, CAST(\u0027ALGO_DECISION_TREE\u0027 AS VARCHAR(50)) AS ALGO_NAME \nFROM CLAIMS_LIFT_TABLE_DT\nUNION\nSELECT QUANTILE_NUMBER, ROUND(GAIN_CUMULATIVE*100,2) GAIN_CUMULATIVE, CAST(\u0027ALGO_SUPPORT_VECTOR_MACHINES\u0027 AS VARCHAR(50)) AS ALGO_NAME \nFROM CLAIMS_LIFT_TABLE_SVM\nUNION\nSELECT QUANTILE_NUMBER, ROUND(GAIN_CUMULATIVE*100,2) GAIN_CUMULATIVE, CAST(\u0027ALGO_RANDOM_FOREST\u0027 AS VARCHAR(50)) AS ALGO_NAME \nFROM CLAIMS_LIFT_TABLE_RF\nUNION\nSELECT QUANTILE_NUMBER, ROUND(GAIN_CUMULATIVE*100,2) GAIN_CUMULATIVE, CAST(\u0027ALGO_GENERALIZED_LINEAR_MODEL\u0027 AS VARCHAR(50)) AS ALGO_NAME \nFROM CLAIMS_LIFT_TABLE_GLM"
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%sql\n\nCREATE OR REPLACE VIEW LIFT_STATS AS \nSELECT QUANTILE_NUMBER, GAIN_CUMULATIVE, ALGO_NAME\nFROM ALL_LIFT_DATA\nUNION \nSELECT QUANTILE_NUMBER, QUANTILE_NUMBER, \u0027RANDOM_GUESS\u0027\nFROM ALL_LIFT_DATA"
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%sql\nSELECT * FROM LIFT_STATS"
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%sql\n\nSELECT *\nFROM CLAIMS_LIFT_TABLE_SVM"
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%python\nimport pandas as pd\nimport oml\n\nimport matplotlib\nimport matplotlib.pyplot as plt\n\n\nLIFT_DF \u003d oml.sync(view \u003d \u0027ALL_LIFT_DATA\u0027)\n\nALGOS \u003d LIFT_DF[\u0027ALGO_NAME\u0027].drop_duplicates()\nlift_df \u003d LIFT_DF.pull()\n\nalgo_list \u003d ALGOS.pull()\nfig, ax \u003d plt.subplots()\n\n\nfig.set_figheight(8)\nfig.set_figwidth(10)\n\nax.set_title(\u0027Lift Curve\u0027)\nax.plot([0, 100], [0, 100], lw\u003d2, linestyle\u003d\u0027--\u0027, color\u003d\u0027red\u0027, label\u003d\u0027Random guess\u0027)\nax.set_xlim([-2, 102])\nax.set_ylim([0, 102])\nax.legend(loc\u003d\"lower right\")\n\npalette \u003d [\u0027blue\u0027, \u0027cyan\u0027, \u0027green\u0027, \u0027orange\u0027]\n\ncolors \u003d dict()\n\nfor i, algo in enumerate(algo_list):\n    colors[algo] \u003d palette[i]\n\nfor algo in algo_list:\n\n    x \u003d lift_df[lift_df[\u0027ALGO_NAME\u0027] \u003d\u003d algo][\u0027QUANTILE_NUMBER\u0027].values\n    x.sort()\n    \n    y \u003d lift_df[lift_df[\u0027ALGO_NAME\u0027] \u003d\u003d algo][\u0027GAIN_CUMULATIVE\u0027].values\n    y.sort()\n    ax.plot(x, y, color\u003dcolors[algo], lw\u003d2, label\u003d\"%s\" % (algo) )\n    ax.legend(loc\u003d\"lower right\")\nplt.style.use(\u0027seaborn\u0027)\nplt.grid(True)\n \nplt.xlabel(\u0027Top percentage (%) \u0027, size\u003d13)\nplt.ylabel(\u0027Recall (%)\u0027, size\u003d13)\n\nplt.show()"
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%python\n\nimport pandas as pd\nimport oml\n\nimport matplotlib\nimport matplotlib.pyplot as plt\n\n\nLIFT_DF \u003d oml.sync(query \u003d \u0027SELECT WIDTH_BUCKET(QUANTILE_NUMBER, 1, 10, 9) QUANTILE_BIN, TARGET_DENSITY FROM CLAIMS_LIFT_TABLE_SVM\u0027)\n\nLIFT_AGG_DF \u003d LIFT_DF.crosstab(index \u003d \u0027QUANTILE_BIN\u0027, values \u003d \u0027TARGET_DENSITY\u0027, aggfunc\u003doml.DataFrame.mean)\n    \nbase \u003d LIFT_DF[\u0027TARGET_DENSITY\u0027].mean()\n\n\ndecile_df \u003d LIFT_AGG_DF.sort_values(\u0027QUANTILE_BIN\u0027, ascending \u003d True).pull()\n\nfig, ax \u003d plt.subplots()\n\n\nfig.set_figheight(8)\nfig.set_figwidth(10)\n\n\nax.set_title(\u0027Waterfall Analysis\u0027)\nax.bar(decile_df[\u0027QUANTILE_BIN\u0027], decile_df[\u0027mean(TARGET_DENSITY)\u0027]*100, color\u003d\u0027blue\u0027, alpha\u003d0.6, label\u003d\u0027Model\u0027)\nax.axhline(base*100, color\u003d\u0027grey\u0027, linestyle\u003d\u0027--\u0027, label\u003d\u0027Avg TARGET\u0027)\nax.legend(loc\u003d\"upper right\")\n    \nax.set_xlabel(\u0027Decile\u0027, size\u003d13)\nax.set_ylabel(\u0027Actual Customers Targeted %\u0027, size\u003d13)\n\nplt.style.use(\u0027seaborn\u0027)\nplt.grid(True)\n \nplt.show()\n    "
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## Apply Model\n\n---\nApplying the model to data, or what\u0027s also referred to as scoring, inferencing, or making predictions, can be performed within SQL queries. We first use the PREDICTION_PROBABILITY function with the GLM model to get the probability that fraud was found (target value \u003d \u0027Yes\u0027). In-database models provide prediction details to explain what predictor values most contributed to the prediction. "
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%sql\nselect round(prob_fraud*100,2) probability_of_fraud,\n      rank() over (order by prob_fraud desc) rnk, \n      POLICYNUMBER, AGEOFPOLICYHOLDER, SEX, MARITALSTATUS \nfrom (select prediction_probability(CLAIMS_CLASS_MODEL_GLM, \u0027Yes\u0027 using *) prob_fraud,POLICYNUMBER, AGEOFPOLICYHOLDER, SEX, MARITALSTATUS\n      from CLAIMS )\norder by probability_of_fraud desc;      \n      \n"
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%sql\n\nSELECT * FROM\n  (select POLICYNUMBER, AGEOFPOLICYHOLDER, SEX, MARITALSTATUS, round(prob_fraud*100,2) probability_of_fraud,\n      rank() over (order by prob_fraud desc) rnk from\n      (select POLICYNUMBER, AGEOFPOLICYHOLDER, SEX, MARITALSTATUS, prediction_probability(CLAIMS_CLASS_MODEL_GLM, \u0027Yes\u0027 using *) prob_fraud\n          from CLAIMS\n))\norder by probability_of_fraud desc;"
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%sql\n\nSELECT * FROM\n   (select POLICYNUMBER, AGEOFPOLICYHOLDER, SEX, MARITALSTATUS, round(prob_fraud*100,2) probability_of_fraud,\n      rank() over (order by prob_fraud desc) rnk from\n      (select POLICYNUMBER, AGEOFPOLICYHOLDER, SEX, MARITALSTATUS, prediction_probability(CLAIMS_CLASS_MODEL_GLM, \u0027No\u0027 using *) prob_fraud\n          from CLAIMS\n))\norder by probability_of_fraud desc;"
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%sql\n\nSELECT PROBABILITY_OF_FRAUD, RNK, POLICYNUMBER, AGEOFPOLICYHOLDER, SEX \nFROM (\nSELECT ROUND(PROB_FRAUD*100,2) PROBABILITY_OF_FRAUD, RANK() OVER (ORDER BY PROB_FRAUD DESC) RNK, POLICYNUMBER, AGEOFPOLICYHOLDER, SEX \n   from\n      (SELECT PREDICTION_PROBABILITY(CLAIMS_CLASS_MODEL_GLM, \u0027Yes\u0027 USING *) PROB_FRAUD, POLICYNUMBER, AGEOFPOLICYHOLDER, SEX \n      from CLAIMS)\n) a\nWHERE RNK \u003c\u003d 5 \nORDER BY PROBABILITY_OF_FRAUD DESC"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "### Display Prediction Details\n\n---"
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%script\n\nBEGIN EXECUTE IMMEDIATE \u0027DROP TABLE SUSPICIOUS_CLAIMS_OAC PURGE\u0027;\nEXCEPTION WHEN OTHERS THEN NULL; END;\n/"
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%sql\n\nCREATE TABLE SUSPICIOUS_CLAIMS_OAC AS \nSELECT res.* , \n       round(PROB_FRAUD*100,2) probability_of_fraud,\n       rank() over (order by prob_fraud desc) rnk \n       from\n           (select cl.*, \n            prediction_probability(CLAIMS_CLASS_MODEL_GLM, \u0027Yes\u0027 using *) PROB_FRAUD, \n            prediction_details(\"CLAIMS_CLASS_MODEL_GLM\", \u0027Yes\u0027, 5 ABS USING *) PREDICTIONDETAILS \n            from CLAIMS cl) res\norder by probability_of_fraud desc;"
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%sql\n\nSELECT RNK,PROBABILITY_OF_FRAUD, PREDICTIONDETAILS, POLICYNUMBER, FRAUDFOUND FROM SUSPICIOUS_CLAIMS_OAC;"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "# End of Script\n"
    },
    {
      "cell_type": "raw",
      "metadata": {
        "format": "text/plain"
      },
      "source": "%script\n"
    }
  ]
}